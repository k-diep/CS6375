{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QP0SXp20lMZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# https://www.kaggle.com/datasets/uciml/iris\n",
        "# This dataset is in the local directory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "  # Constructor\n",
        "  def __init__(self, activation=\"sigmoid\"):\n",
        "    self.df = None\n",
        "    self.input_layer_size = None\n",
        "    self.hidden_layer_size = None\n",
        "    self.output_layer_size = None\n",
        "    self.learning_rate = 0.1\n",
        "\n",
        "    self.X_train = None\n",
        "    self.X_test = None\n",
        "    self.y_train = None\n",
        "    self.y_test = None\n",
        "\n",
        "    self.weights_between_input_hidden = None\n",
        "    self.weights_between_hidden_output = None\n",
        "    self.bias_from_hidden = None\n",
        "    self.bias_from_output = None\n",
        "\n",
        "    self.output_out = None\n",
        "    self.hidden_out = None\n",
        "\n",
        "    self.activation = activation\n",
        "\n",
        "    if activation == 'sigmoid' :\n",
        "      self.activation = 'sigmoid'\n",
        "\n",
        "    elif activation == 'tanh' :\n",
        "      self.activation = 'tanh'\n",
        "\n",
        "    elif activation == 'relu' :\n",
        "      self.activation = 'relu'\n",
        "\n",
        "\n",
        "  #creating  weights\n",
        "  # delete this\n",
        "  #rows, columns = (4,6)\n",
        "  #arr = [[0]*columns]*rows\n",
        "  #print(arr)\n",
        "\n",
        "\n",
        "  #variables for gradient descent optimization\n",
        "  ####CHANGE\n",
        "  decayFact = 0\n",
        "  maxIter = 1000\n",
        "\n",
        "  # ACTIVATION FUNCTIONS ----------------------------------------\n",
        "  # Sigmoid Activation Function\n",
        "  def sigmoid(self, x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "  # Derivative of Sigmoid Function\n",
        "  def sigmoid_derivative(self, x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "  # Tanh Activation Function\n",
        "  def tanh(self, x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "  # Derivative of Tanh Function\n",
        "  def tanh_derivative(self, x):\n",
        "    return 1 - np.tanh(x)**2\n",
        "\n",
        "  # ReLu Activation Function\n",
        "  def relu(self, x):\n",
        "    return np.maximum(0,x)\n",
        "\n",
        "  # Derivative of ReLu Function\n",
        "  def relu_derivative(self, x):\n",
        "    return (x > 0) * 1\n",
        "\n",
        "\n",
        "  # END OF ACTIVATION FUNCTIONS ----------------------------------------\n",
        "\n",
        "  # Getting the dataframe\n",
        "  def load_iris_data(self):\n",
        "    # Load the dataset into a DataFrame\n",
        "    iris_df = pd.read_csv(\"Iris.csv\")\n",
        "    self.df = iris_df\n",
        "\n",
        "  # Manually encode the 'Species' column into numeric values\n",
        "  def encode_species(self):\n",
        "    species_mapping = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n",
        "    self.df['Species'] = self.df['Species'].map(species_mapping)\n",
        "\n",
        "  # Drop the 'Id' column if it exists\n",
        "  def drop_id_column(self):\n",
        "    self.df.drop(columns=['Id'], inplace=True)\n",
        "\n",
        "  def preprocess_iris_dataset(self):\n",
        "    self.encode_species()\n",
        "    self.drop_id_column()\n",
        "\n",
        "  # Split the df into training and testing datasets\n",
        "  def split_dataset(self, test_size=0.2, random_state=69):\n",
        "    np.random.seed(random_state)\n",
        "    shuffled_indices = np.random.permutation(len(self.df))\n",
        "\n",
        "    test_set_size = int(len(self.df) * test_size)\n",
        "    test_indices = shuffled_indices[:test_set_size]\n",
        "    train_indices = shuffled_indices[test_set_size:]\n",
        "\n",
        "    self.X_train = self.df.iloc[train_indices].drop(columns=['Species']).reset_index(drop=True)\n",
        "    self.X_test = self.df.iloc[test_indices].drop(columns=['Species']).reset_index(drop=True)\n",
        "    self.y_train = self.df.iloc[train_indices]['Species'].reset_index(drop=True)\n",
        "    self.y_test = self.df.iloc[test_indices]['Species'].reset_index(drop=True)\n",
        "\n",
        "  # Should be 4, since the number of attributes of the dataset is 4\n",
        "  def set_input_size(self):\n",
        "    num_columns = self.X_train.shape[1]\n",
        "    self.input_layer_size = num_columns\n",
        "\n",
        "  # Should be 3, since the number of categories in the dataset is 3\n",
        "  def set_output_size(self):\n",
        "    unique_values_count = self.y_train.nunique()\n",
        "    self.output_layer_size = unique_values_count\n",
        "\n",
        "  # Will only have one hidden layer of size n (default of 6 nodes)\n",
        "  def set_attributes(self, hidden_layer_size = 6):\n",
        "    self.set_input_size()\n",
        "    self.set_output_size()\n",
        "    self.hidden_layer_size = hidden_layer_size\n",
        "\n",
        "  def show_attributes(self):\n",
        "    print(\"Input Size: \" , self.input_layer_size)\n",
        "    print(\"Hidden Size: \" , self.hidden_layer_size)\n",
        "    print(\"Output Size: \" , self.output_layer_size)\n",
        "\n",
        "  # Creating the weights between each Layer as well as the Biases\n",
        "  def create_weights_bias(self):\n",
        "    self.weights_between_input_hidden = np.random.randn(self.input_layer_size, self.hidden_layer_size)\n",
        "    self.weights_between_hidden_output = np.random.randn(self.hidden_layer_size, self.output_layer_size)\n",
        "    self.bias_from_hidden = np.random.randn(self.hidden_layer_size)\n",
        "    self.bias_from_output = np.random.randn(self.output_layer_size)\n",
        "\n",
        "\n",
        "  # Forward Propagation\n",
        "  def forward_propagation(self, X):\n",
        "    hidden_net = np.dot(X, self.weights_between_input_hidden) + self.bias_from_hidden\n",
        "    if self.activation == 'sigmoid':\n",
        "      self.hidden_out = self.sigmoid(hidden_net)\n",
        "    if self.activation == 'tanh':\n",
        "      self.hidden_out = self.tanh(hidden_net)\n",
        "    if self.activation == 'relu':\n",
        "      self.hidden_out = self.relu(hidden_net)\n",
        "\n",
        "    output_net = np.dot(self.hidden_out, self.weights_between_hidden_output) + self.bias_from_output\n",
        "    if self.activation == 'sigmoid':\n",
        "      self.output_out = self.sigmoid(output_net)\n",
        "    if self.activation == 'tanh':\n",
        "      self.output_out = self.tanh(output_net)\n",
        "    if self.activation == 'relu':\n",
        "      self.output_out = self.relu(output_net)\n",
        "\n",
        "  # Backward Propagation\n",
        "  def backward_propogation(self, X, y):\n",
        "    error = y - self.output_out\n",
        "    if self.activation == 'sigmoid':\n",
        "      delta_output = self.sigmoid_derivative(self.output_out) * error\n",
        "      delta_hidden = self.weights_between_hidden_output.dot(delta_output) * self.sigmoid_derivative(self.hidden_out)\n",
        "\n",
        "\n",
        "    if self.activation == 'tanh':\n",
        "      delta_output = self.tanh_derivative(self.output_out) * error\n",
        "      delta_hidden = self.weights_between_hidden_output.dot(delta_output) * self.tanh_derivative(self.hidden_out)\n",
        "\n",
        "    if self.activation == 'relu':\n",
        "      delta_output = self.relu_derivative(self.output_out) * error\n",
        "      delta_hidden = self.weights_between_hidden_output.dot(delta_output) * self.relu_derivative(self.hidden_out)\n",
        "\n",
        "\n",
        "    # Update Weights\n",
        "\n",
        "    self.weights_between_hidden_output +=  np.outer(self.hidden_out, delta_output) * self.learning_rate\n",
        "    self.weights_between_input_hidden += np.outer(X, delta_hidden) * self.learning_rate\n",
        "\n",
        "    #Update Bias\n",
        "    self.bias_from_output += np.sum(delta_output, axis=0) * self.learning_rate\n",
        "    self.bias_from_hidden += np.sum(delta_hidden, axis=0) * self.learning_rate\n",
        "\n",
        "\n",
        "  # Used to encode the y values\n",
        "  def one_hot_encode(self, index, size):\n",
        "    encoded = np.zeros(size)\n",
        "    encoded[index] = 1\n",
        "    return encoded\n",
        "\n",
        "  def train(self, activation = 'sigmoid', learning_rate = 0.1, epochs = 10):\n",
        "    # Changing the activation\n",
        "    if activation == 'tanh':\n",
        "      self.activation = 'tanh'\n",
        "\n",
        "    elif activation == 'relu':\n",
        "      self.activation = 'relu'\n",
        "\n",
        "    self.learning_rate = learning_rate\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "      correct_prediction   = 0\n",
        "      incorrect_prediction = 0\n",
        "\n",
        "      for (index_X, row_X), (index_Y, row_Y) in zip(self.X_train.iterrows(), pd.DataFrame(self.y_train).iterrows()):\n",
        "        X_row = row_X.to_numpy()\n",
        "        y_value = row_Y.to_numpy()[0]\n",
        "\n",
        "        y_encode = self.one_hot_encode(y_value, self.output_layer_size)\n",
        "\n",
        "        self.forward_propagation(X_row)\n",
        "        self.backward_propogation(X_row, y_encode)\n",
        "\n",
        "        max_index = np.argmax(self.output_out)\n",
        "        if y_encode[max_index] !=0:\n",
        "          correct_prediction += 1\n",
        "        else:\n",
        "          incorrect_prediction +=1\n",
        "      print(\"Epoch: \", epoch + 1)\n",
        "      print(\"Correct Predictions: \", correct_prediction)\n",
        "      print(\"Incorrect Predictions: \", incorrect_prediction)\n",
        "      print(\"Accuracy: \", correct_prediction / (incorrect_prediction+correct_prediction))\n",
        "      print()\n",
        "\n",
        "  def test(self):\n",
        "    correct_prediction   = 0\n",
        "    incorrect_prediction = 0\n",
        "\n",
        "    for (index_X, row_X), (index_Y, row_Y) in zip(self.X_test.iterrows(), pd.DataFrame(self.y_test).iterrows()):\n",
        "      X_row = row_X.to_numpy()\n",
        "      y_value = row_Y.to_numpy()[0]\n",
        "      y_encode = self.one_hot_encode(y_value, self.output_layer_size)\n",
        "      self.forward_propagation(X_row)\n",
        "      max_index = np.argmax(self.output_out)\n",
        "      if y_encode[max_index] !=0:\n",
        "        correct_prediction += 1\n",
        "      else:\n",
        "        incorrect_prediction +=1\n",
        "\n",
        "    print(\"Testing Dataset\")\n",
        "    print(\"Correct Predictions: \", correct_prediction)\n",
        "    print(\"Incorrect Predictions: \", incorrect_prediction)\n",
        "    print(\"Accuracy: \", correct_prediction / (incorrect_prediction+correct_prediction))\n",
        "    print()\n",
        "\n",
        "  # Setters (used for testing)\n",
        "  def set_learning_rate(self, learning_rate):\n",
        "    self.learning_rate = learning_rate\n",
        "\n",
        "  def set_activation(self, activation):\n",
        "    self.activation = activation\n",
        "\n",
        "  # Getters\n",
        "  def get_X_train(self):\n",
        "    return self.X_train\n",
        "\n",
        "  def get_X_test(self):\n",
        "    return self.X_test\n",
        "\n",
        "  def get_y_train(self):\n",
        "    return self.y_train\n",
        "\n",
        "  def get_y_test(self):\n",
        "    return self.y_test\n",
        "\n",
        "  def get_activation(self):\n",
        "    return self.activation\n",
        "\n",
        "  # Print Statements\n",
        "  # Used for debugging/testing\n",
        "\n",
        "  # Print the head of our dataset\n",
        "  def print_head(self):\n",
        "    print(self.df.head())\n",
        "\n",
        "  # Shows each bias/weight array\n",
        "  def show_weight_bias(self):\n",
        "    print(\"weights_between_input_hidden\")\n",
        "    print(self.weights_between_input_hidden)\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"weights_between_hidden_output\")\n",
        "    print(self.weights_between_hidden_output)\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"bias_from_hidden\")\n",
        "    print(self.bias_from_hidden)\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"bias_from_output\")\n",
        "    print(self.bias_from_output)\n",
        "    print(\"\\n\\n\")"
      ],
      "metadata": {
        "id": "gO_6b78px1qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling the class\n",
        "nn = NeuralNetwork(activation=\"sigmoid\")\n",
        "\n",
        "# Loading the data\n",
        "nn.load_iris_data()\n",
        "nn.preprocess_iris_dataset()\n",
        "nn.split_dataset(random_state=2)\n",
        "# Create the input, hidden, and output layers.\n",
        "# Hidden layer has default 6 neurons\n",
        "# Can change hidden_layer_size\n",
        "#nn.set_attributes(hidden_layer_size=10)\n",
        "nn.set_attributes()\n",
        "nn.show_attributes()\n",
        "print(\"\\n\")\n",
        "nn.create_weights_bias()\n",
        "\n",
        "nn.train(epochs = 100, activation=\"tanh\", learning_rate = 0.01)\n",
        "nn.test()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrynO5cC3nQA",
        "outputId": "4bb89619-fe30-4f40-f398-468fc01fdbfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Size:  4\n",
            "Hidden Size:  6\n",
            "Output Size:  3\n",
            "\n",
            "\n",
            "Epoch:  1\n",
            "Correct Predictions:  49\n",
            "Incorrect Predictions:  71\n",
            "Accuracy:  0.4083333333333333\n",
            "\n",
            "Epoch:  2\n",
            "Correct Predictions:  87\n",
            "Incorrect Predictions:  33\n",
            "Accuracy:  0.725\n",
            "\n",
            "Epoch:  3\n",
            "Correct Predictions:  93\n",
            "Incorrect Predictions:  27\n",
            "Accuracy:  0.775\n",
            "\n",
            "Epoch:  4\n",
            "Correct Predictions:  95\n",
            "Incorrect Predictions:  25\n",
            "Accuracy:  0.7916666666666666\n",
            "\n",
            "Epoch:  5\n",
            "Correct Predictions:  102\n",
            "Incorrect Predictions:  18\n",
            "Accuracy:  0.85\n",
            "\n",
            "Epoch:  6\n",
            "Correct Predictions:  103\n",
            "Incorrect Predictions:  17\n",
            "Accuracy:  0.8583333333333333\n",
            "\n",
            "Epoch:  7\n",
            "Correct Predictions:  104\n",
            "Incorrect Predictions:  16\n",
            "Accuracy:  0.8666666666666667\n",
            "\n",
            "Epoch:  8\n",
            "Correct Predictions:  104\n",
            "Incorrect Predictions:  16\n",
            "Accuracy:  0.8666666666666667\n",
            "\n",
            "Epoch:  9\n",
            "Correct Predictions:  107\n",
            "Incorrect Predictions:  13\n",
            "Accuracy:  0.8916666666666667\n",
            "\n",
            "Epoch:  10\n",
            "Correct Predictions:  108\n",
            "Incorrect Predictions:  12\n",
            "Accuracy:  0.9\n",
            "\n",
            "Epoch:  11\n",
            "Correct Predictions:  108\n",
            "Incorrect Predictions:  12\n",
            "Accuracy:  0.9\n",
            "\n",
            "Epoch:  12\n",
            "Correct Predictions:  108\n",
            "Incorrect Predictions:  12\n",
            "Accuracy:  0.9\n",
            "\n",
            "Epoch:  13\n",
            "Correct Predictions:  108\n",
            "Incorrect Predictions:  12\n",
            "Accuracy:  0.9\n",
            "\n",
            "Epoch:  14\n",
            "Correct Predictions:  109\n",
            "Incorrect Predictions:  11\n",
            "Accuracy:  0.9083333333333333\n",
            "\n",
            "Epoch:  15\n",
            "Correct Predictions:  109\n",
            "Incorrect Predictions:  11\n",
            "Accuracy:  0.9083333333333333\n",
            "\n",
            "Epoch:  16\n",
            "Correct Predictions:  109\n",
            "Incorrect Predictions:  11\n",
            "Accuracy:  0.9083333333333333\n",
            "\n",
            "Epoch:  17\n",
            "Correct Predictions:  109\n",
            "Incorrect Predictions:  11\n",
            "Accuracy:  0.9083333333333333\n",
            "\n",
            "Epoch:  18\n",
            "Correct Predictions:  109\n",
            "Incorrect Predictions:  11\n",
            "Accuracy:  0.9083333333333333\n",
            "\n",
            "Epoch:  19\n",
            "Correct Predictions:  109\n",
            "Incorrect Predictions:  11\n",
            "Accuracy:  0.9083333333333333\n",
            "\n",
            "Epoch:  20\n",
            "Correct Predictions:  109\n",
            "Incorrect Predictions:  11\n",
            "Accuracy:  0.9083333333333333\n",
            "\n",
            "Epoch:  21\n",
            "Correct Predictions:  110\n",
            "Incorrect Predictions:  10\n",
            "Accuracy:  0.9166666666666666\n",
            "\n",
            "Epoch:  22\n",
            "Correct Predictions:  110\n",
            "Incorrect Predictions:  10\n",
            "Accuracy:  0.9166666666666666\n",
            "\n",
            "Epoch:  23\n",
            "Correct Predictions:  110\n",
            "Incorrect Predictions:  10\n",
            "Accuracy:  0.9166666666666666\n",
            "\n",
            "Epoch:  24\n",
            "Correct Predictions:  110\n",
            "Incorrect Predictions:  10\n",
            "Accuracy:  0.9166666666666666\n",
            "\n",
            "Epoch:  25\n",
            "Correct Predictions:  110\n",
            "Incorrect Predictions:  10\n",
            "Accuracy:  0.9166666666666666\n",
            "\n",
            "Epoch:  26\n",
            "Correct Predictions:  110\n",
            "Incorrect Predictions:  10\n",
            "Accuracy:  0.9166666666666666\n",
            "\n",
            "Epoch:  27\n",
            "Correct Predictions:  110\n",
            "Incorrect Predictions:  10\n",
            "Accuracy:  0.9166666666666666\n",
            "\n",
            "Epoch:  28\n",
            "Correct Predictions:  110\n",
            "Incorrect Predictions:  10\n",
            "Accuracy:  0.9166666666666666\n",
            "\n",
            "Epoch:  29\n",
            "Correct Predictions:  110\n",
            "Incorrect Predictions:  10\n",
            "Accuracy:  0.9166666666666666\n",
            "\n",
            "Epoch:  30\n",
            "Correct Predictions:  110\n",
            "Incorrect Predictions:  10\n",
            "Accuracy:  0.9166666666666666\n",
            "\n",
            "Epoch:  31\n",
            "Correct Predictions:  110\n",
            "Incorrect Predictions:  10\n",
            "Accuracy:  0.9166666666666666\n",
            "\n",
            "Epoch:  32\n",
            "Correct Predictions:  110\n",
            "Incorrect Predictions:  10\n",
            "Accuracy:  0.9166666666666666\n",
            "\n",
            "Epoch:  33\n",
            "Correct Predictions:  110\n",
            "Incorrect Predictions:  10\n",
            "Accuracy:  0.9166666666666666\n",
            "\n",
            "Epoch:  34\n",
            "Correct Predictions:  110\n",
            "Incorrect Predictions:  10\n",
            "Accuracy:  0.9166666666666666\n",
            "\n",
            "Epoch:  35\n",
            "Correct Predictions:  110\n",
            "Incorrect Predictions:  10\n",
            "Accuracy:  0.9166666666666666\n",
            "\n",
            "Epoch:  36\n",
            "Correct Predictions:  110\n",
            "Incorrect Predictions:  10\n",
            "Accuracy:  0.9166666666666666\n",
            "\n",
            "Epoch:  37\n",
            "Correct Predictions:  110\n",
            "Incorrect Predictions:  10\n",
            "Accuracy:  0.9166666666666666\n",
            "\n",
            "Epoch:  38\n",
            "Correct Predictions:  111\n",
            "Incorrect Predictions:  9\n",
            "Accuracy:  0.925\n",
            "\n",
            "Epoch:  39\n",
            "Correct Predictions:  111\n",
            "Incorrect Predictions:  9\n",
            "Accuracy:  0.925\n",
            "\n",
            "Epoch:  40\n",
            "Correct Predictions:  111\n",
            "Incorrect Predictions:  9\n",
            "Accuracy:  0.925\n",
            "\n",
            "Epoch:  41\n",
            "Correct Predictions:  111\n",
            "Incorrect Predictions:  9\n",
            "Accuracy:  0.925\n",
            "\n",
            "Epoch:  42\n",
            "Correct Predictions:  111\n",
            "Incorrect Predictions:  9\n",
            "Accuracy:  0.925\n",
            "\n",
            "Epoch:  43\n",
            "Correct Predictions:  112\n",
            "Incorrect Predictions:  8\n",
            "Accuracy:  0.9333333333333333\n",
            "\n",
            "Epoch:  44\n",
            "Correct Predictions:  112\n",
            "Incorrect Predictions:  8\n",
            "Accuracy:  0.9333333333333333\n",
            "\n",
            "Epoch:  45\n",
            "Correct Predictions:  112\n",
            "Incorrect Predictions:  8\n",
            "Accuracy:  0.9333333333333333\n",
            "\n",
            "Epoch:  46\n",
            "Correct Predictions:  112\n",
            "Incorrect Predictions:  8\n",
            "Accuracy:  0.9333333333333333\n",
            "\n",
            "Epoch:  47\n",
            "Correct Predictions:  112\n",
            "Incorrect Predictions:  8\n",
            "Accuracy:  0.9333333333333333\n",
            "\n",
            "Epoch:  48\n",
            "Correct Predictions:  112\n",
            "Incorrect Predictions:  8\n",
            "Accuracy:  0.9333333333333333\n",
            "\n",
            "Epoch:  49\n",
            "Correct Predictions:  112\n",
            "Incorrect Predictions:  8\n",
            "Accuracy:  0.9333333333333333\n",
            "\n",
            "Epoch:  50\n",
            "Correct Predictions:  112\n",
            "Incorrect Predictions:  8\n",
            "Accuracy:  0.9333333333333333\n",
            "\n",
            "Epoch:  51\n",
            "Correct Predictions:  112\n",
            "Incorrect Predictions:  8\n",
            "Accuracy:  0.9333333333333333\n",
            "\n",
            "Epoch:  52\n",
            "Correct Predictions:  112\n",
            "Incorrect Predictions:  8\n",
            "Accuracy:  0.9333333333333333\n",
            "\n",
            "Epoch:  53\n",
            "Correct Predictions:  112\n",
            "Incorrect Predictions:  8\n",
            "Accuracy:  0.9333333333333333\n",
            "\n",
            "Epoch:  54\n",
            "Correct Predictions:  112\n",
            "Incorrect Predictions:  8\n",
            "Accuracy:  0.9333333333333333\n",
            "\n",
            "Epoch:  55\n",
            "Correct Predictions:  112\n",
            "Incorrect Predictions:  8\n",
            "Accuracy:  0.9333333333333333\n",
            "\n",
            "Epoch:  56\n",
            "Correct Predictions:  112\n",
            "Incorrect Predictions:  8\n",
            "Accuracy:  0.9333333333333333\n",
            "\n",
            "Epoch:  57\n",
            "Correct Predictions:  112\n",
            "Incorrect Predictions:  8\n",
            "Accuracy:  0.9333333333333333\n",
            "\n",
            "Epoch:  58\n",
            "Correct Predictions:  112\n",
            "Incorrect Predictions:  8\n",
            "Accuracy:  0.9333333333333333\n",
            "\n",
            "Epoch:  59\n",
            "Correct Predictions:  112\n",
            "Incorrect Predictions:  8\n",
            "Accuracy:  0.9333333333333333\n",
            "\n",
            "Epoch:  60\n",
            "Correct Predictions:  112\n",
            "Incorrect Predictions:  8\n",
            "Accuracy:  0.9333333333333333\n",
            "\n",
            "Epoch:  61\n",
            "Correct Predictions:  112\n",
            "Incorrect Predictions:  8\n",
            "Accuracy:  0.9333333333333333\n",
            "\n",
            "Epoch:  62\n",
            "Correct Predictions:  112\n",
            "Incorrect Predictions:  8\n",
            "Accuracy:  0.9333333333333333\n",
            "\n",
            "Epoch:  63\n",
            "Correct Predictions:  113\n",
            "Incorrect Predictions:  7\n",
            "Accuracy:  0.9416666666666667\n",
            "\n",
            "Epoch:  64\n",
            "Correct Predictions:  113\n",
            "Incorrect Predictions:  7\n",
            "Accuracy:  0.9416666666666667\n",
            "\n",
            "Epoch:  65\n",
            "Correct Predictions:  113\n",
            "Incorrect Predictions:  7\n",
            "Accuracy:  0.9416666666666667\n",
            "\n",
            "Epoch:  66\n",
            "Correct Predictions:  113\n",
            "Incorrect Predictions:  7\n",
            "Accuracy:  0.9416666666666667\n",
            "\n",
            "Epoch:  67\n",
            "Correct Predictions:  113\n",
            "Incorrect Predictions:  7\n",
            "Accuracy:  0.9416666666666667\n",
            "\n",
            "Epoch:  68\n",
            "Correct Predictions:  113\n",
            "Incorrect Predictions:  7\n",
            "Accuracy:  0.9416666666666667\n",
            "\n",
            "Epoch:  69\n",
            "Correct Predictions:  113\n",
            "Incorrect Predictions:  7\n",
            "Accuracy:  0.9416666666666667\n",
            "\n",
            "Epoch:  70\n",
            "Correct Predictions:  113\n",
            "Incorrect Predictions:  7\n",
            "Accuracy:  0.9416666666666667\n",
            "\n",
            "Epoch:  71\n",
            "Correct Predictions:  113\n",
            "Incorrect Predictions:  7\n",
            "Accuracy:  0.9416666666666667\n",
            "\n",
            "Epoch:  72\n",
            "Correct Predictions:  113\n",
            "Incorrect Predictions:  7\n",
            "Accuracy:  0.9416666666666667\n",
            "\n",
            "Epoch:  73\n",
            "Correct Predictions:  114\n",
            "Incorrect Predictions:  6\n",
            "Accuracy:  0.95\n",
            "\n",
            "Epoch:  74\n",
            "Correct Predictions:  114\n",
            "Incorrect Predictions:  6\n",
            "Accuracy:  0.95\n",
            "\n",
            "Epoch:  75\n",
            "Correct Predictions:  115\n",
            "Incorrect Predictions:  5\n",
            "Accuracy:  0.9583333333333334\n",
            "\n",
            "Epoch:  76\n",
            "Correct Predictions:  116\n",
            "Incorrect Predictions:  4\n",
            "Accuracy:  0.9666666666666667\n",
            "\n",
            "Epoch:  77\n",
            "Correct Predictions:  116\n",
            "Incorrect Predictions:  4\n",
            "Accuracy:  0.9666666666666667\n",
            "\n",
            "Epoch:  78\n",
            "Correct Predictions:  116\n",
            "Incorrect Predictions:  4\n",
            "Accuracy:  0.9666666666666667\n",
            "\n",
            "Epoch:  79\n",
            "Correct Predictions:  116\n",
            "Incorrect Predictions:  4\n",
            "Accuracy:  0.9666666666666667\n",
            "\n",
            "Epoch:  80\n",
            "Correct Predictions:  117\n",
            "Incorrect Predictions:  3\n",
            "Accuracy:  0.975\n",
            "\n",
            "Epoch:  81\n",
            "Correct Predictions:  117\n",
            "Incorrect Predictions:  3\n",
            "Accuracy:  0.975\n",
            "\n",
            "Epoch:  82\n",
            "Correct Predictions:  117\n",
            "Incorrect Predictions:  3\n",
            "Accuracy:  0.975\n",
            "\n",
            "Epoch:  83\n",
            "Correct Predictions:  117\n",
            "Incorrect Predictions:  3\n",
            "Accuracy:  0.975\n",
            "\n",
            "Epoch:  84\n",
            "Correct Predictions:  117\n",
            "Incorrect Predictions:  3\n",
            "Accuracy:  0.975\n",
            "\n",
            "Epoch:  85\n",
            "Correct Predictions:  117\n",
            "Incorrect Predictions:  3\n",
            "Accuracy:  0.975\n",
            "\n",
            "Epoch:  86\n",
            "Correct Predictions:  117\n",
            "Incorrect Predictions:  3\n",
            "Accuracy:  0.975\n",
            "\n",
            "Epoch:  87\n",
            "Correct Predictions:  117\n",
            "Incorrect Predictions:  3\n",
            "Accuracy:  0.975\n",
            "\n",
            "Epoch:  88\n",
            "Correct Predictions:  117\n",
            "Incorrect Predictions:  3\n",
            "Accuracy:  0.975\n",
            "\n",
            "Epoch:  89\n",
            "Correct Predictions:  117\n",
            "Incorrect Predictions:  3\n",
            "Accuracy:  0.975\n",
            "\n",
            "Epoch:  90\n",
            "Correct Predictions:  117\n",
            "Incorrect Predictions:  3\n",
            "Accuracy:  0.975\n",
            "\n",
            "Epoch:  91\n",
            "Correct Predictions:  117\n",
            "Incorrect Predictions:  3\n",
            "Accuracy:  0.975\n",
            "\n",
            "Epoch:  92\n",
            "Correct Predictions:  117\n",
            "Incorrect Predictions:  3\n",
            "Accuracy:  0.975\n",
            "\n",
            "Epoch:  93\n",
            "Correct Predictions:  117\n",
            "Incorrect Predictions:  3\n",
            "Accuracy:  0.975\n",
            "\n",
            "Epoch:  94\n",
            "Correct Predictions:  117\n",
            "Incorrect Predictions:  3\n",
            "Accuracy:  0.975\n",
            "\n",
            "Epoch:  95\n",
            "Correct Predictions:  117\n",
            "Incorrect Predictions:  3\n",
            "Accuracy:  0.975\n",
            "\n",
            "Epoch:  96\n",
            "Correct Predictions:  117\n",
            "Incorrect Predictions:  3\n",
            "Accuracy:  0.975\n",
            "\n",
            "Epoch:  97\n",
            "Correct Predictions:  117\n",
            "Incorrect Predictions:  3\n",
            "Accuracy:  0.975\n",
            "\n",
            "Epoch:  98\n",
            "Correct Predictions:  117\n",
            "Incorrect Predictions:  3\n",
            "Accuracy:  0.975\n",
            "\n",
            "Epoch:  99\n",
            "Correct Predictions:  117\n",
            "Incorrect Predictions:  3\n",
            "Accuracy:  0.975\n",
            "\n",
            "Epoch:  100\n",
            "Correct Predictions:  117\n",
            "Incorrect Predictions:  3\n",
            "Accuracy:  0.975\n",
            "\n",
            "Testing Dataset\n",
            "Correct Predictions:  27\n",
            "Incorrect Predictions:  3\n",
            "Accuracy:  0.9\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "from numpy.random import permutation\n",
        "\n",
        "# Attempting anoter\n",
        "#class for gradient Descent line\n",
        "\n",
        "#this is what'll be used for the model\n",
        "#2 weights w0 - intercept and w1 - slope\n",
        "class Line():\n",
        "\n",
        "  def __init__(self):\n",
        "    self.weights = [np.random.uniform(0,1,1) for _ in range(2)]\n",
        "    self.derivateFuncs = [self.dx_w0, self.dx_w1]\n",
        "\n",
        "\n",
        "#will evaluate line yhat given x\n",
        "\n",
        "  def evaluate(self, x):\n",
        "    return self.weights[0]+ self.weights[1] *x\n",
        "\n",
        "#calculates all parital deviatives and returns them\n",
        "#x point on plane\n",
        "#y is output of x\n",
        "# returns an array of partial derviatives\n",
        "  def derivate(self, x, y):\n",
        "    partialDerivs = []\n",
        "\n",
        "    yHat = self.evaluate(x)\n",
        "    partialDerivs.append(self.dx_w0(x, y, yHat ))\n",
        "    partialDerivs.append(self.dx_w1(x, y, yHat ))\n",
        "\n",
        "    return partialDerivs\n",
        "\n",
        "\n",
        "# parital derviative of w0\n",
        "#returns the gradient at that point for x and y\n",
        "  def dx_w0(self, x, y, yHat):\n",
        "    return 2*(yHat-y)\n",
        "\n",
        "#partial derivative of w1\n",
        "#returns gradient at w1\n",
        "  def dx_w1(self, x, y, yHat):\n",
        "    return 2*x*(yHat-y)\n",
        "\n",
        "  def __str__(self):\n",
        "    return f\"y = {self.weights[0]} + {self.weights[1]} * x\"\n",
        "\n",
        "\n",
        "#helper functions\n",
        "\n",
        "\n",
        "#returns one randomly selected x and y\n",
        "#xs all points on plane\n",
        "#y all outputs on plane\n",
        "def stochastic(xs, ys):\n",
        "   perm = permutation(len(xs))\n",
        "   x = xs[perm[0]]\n",
        "   y = ys[perm[0]]\n",
        "\n",
        "   return x, y\n",
        "\n",
        "#estimates mean gradient over all point for w1\n",
        "#returns mean gradient all x and y for w1\n",
        "def gradient(dx, evaluate, xs, ys):\n",
        "   N = len(ys)\n",
        "   total = 0\n",
        "   for x, y in zip(xs, ys):\n",
        "     yHat = evaluate(x)\n",
        "     total = total + dx(x, y, yHat)\n",
        "\n",
        "   gradient = total/N\n",
        "   return gradient\n",
        "\n",
        "\n",
        "\n",
        "#gradient descent optimization\n",
        "# built on momentum model\n",
        "#model: Line class\n",
        "#xs: feature of dataset\n",
        "# ys the continous value (target)\n",
        "#learning rate is learning rate\n",
        "# decayFact is decay Factor\n",
        "# maxIter is maximum number of iterations\n",
        "def nesterov(model, xs, ys, learningRate, decayFact, maxIter):\n",
        "\n",
        "  #needed to keep track of previous geradient\n",
        "  g = [0 for _ in range(len(model.weights))]\n",
        "\n",
        "  for i in range(maxIter):\n",
        "\n",
        "    #choosing random x and y\n",
        "    x, y = stochastic(xs,ys)\n",
        "\n",
        "    #calculating the gradient\n",
        "    for idx, gradient in enumerate(model.derivate(x,y)):\n",
        "      prevWeight = model.weights[idx]\n",
        "      model.weiths[idx] = decayFact * gradient\n",
        "      g[idx] = decayFact*g[idx] + learningRate*gradient\n",
        "      model.weights[idx] = prevWeight\n",
        "\n",
        "      #updating the model parameters\n",
        "      model.weights[idx] = model.weights[idx] - g[idx]\n",
        "\n",
        "    if i % 100 == 0:\n",
        "      print(f\"iteration is {i}\")\n",
        "      print(model)\n",
        "\n",
        "\"\"\"\n",
        "class Optimizers:\n",
        "  def __init__(self, learning_rate):\n",
        "    self.learning_rate = learning_rate\n",
        "\n",
        "  def SGD(self,  params, grads):\n",
        "    #Stochastic gradient descent\n",
        "    updated_params = []\n",
        "\n",
        "    for param, grad  in zip(params, grads):\n",
        "        delta = self.learning_rate * grad\n",
        "        param -= delta\n",
        "\n",
        "        updated_params.apppend(\n",
        "          param\n",
        "        )\n",
        "\n",
        "    return updated_params\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "K_QFRsNSFl7A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "818bdab8-303f-4ae6-e4ef-2d4e8f578fe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass Optimizers:\\n  def __init__(self, learning_rate):\\n    self.learning_rate = learning_rate\\n\\n  def SGD(self,  params, grads):\\n    #Stochastic gradient descent\\n    updated_params = []\\n\\n    for param, grad  in zip(params, grads):\\n        delta = self.learning_rate * grad\\n        param -= delta\\n\\n        updated_params.apppend(\\n          param\\n        )\\n\\n    return updated_params\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    }
  ]
}