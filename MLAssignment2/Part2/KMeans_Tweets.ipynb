{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uVfZYeDw9Drr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class KMeans:\n",
        "  def __init__(self):\n",
        "    self.k = None\n",
        "    self.file_name = None\n",
        "    self.cleaned_lines = None\n",
        "\n",
        "  # Read the file in and preprocess it\n",
        "  def read_file(self, file_name):\n",
        "    # Read the text file line by line\n",
        "    self.file_name = file_name\n",
        "\n",
        "    with open(file_name, 'r') as file:\n",
        "      lines = file.readlines()\n",
        "\n",
        "    # Remove the tweet id and timestamp\n",
        "    cleaned_lines = [line.split('|', 2)[-1] for line in lines]\n",
        "\n",
        "    # Remove any word that starts with the symbol @\n",
        "    pattern = r'@\\w+\\s?'\n",
        "    cleaned_lines = [re.sub(pattern, '', line) for line in cleaned_lines]\n",
        "\n",
        "    # Remove '#' symbols\n",
        "    pattern = r'#'\n",
        "    cleaned_lines = [re.sub(pattern, '', line) for line in cleaned_lines]\n",
        "\n",
        "    # Remove any URL\n",
        "    pattern = r'https?://\\S+|www\\.\\S+'\n",
        "    cleaned_lines = [re.sub(pattern, '', line) for line in cleaned_lines]\n",
        "\n",
        "    # Remove punctuations\n",
        "    pattern =  r'[^\\w\\s]'\n",
        "    cleaned_lines = [re.sub(pattern, '', line) for line in cleaned_lines]\n",
        "\n",
        "    # Remove new lines\n",
        "    pattern = r'\\n'\n",
        "    cleaned_lines = [re.sub(pattern, '', line) for line in cleaned_lines]\n",
        "\n",
        "    # Convert every word to lowercase\n",
        "    self.cleaned_lines = [line.lower() for line in cleaned_lines]\n",
        "\n",
        "    return self.cleaned_lines\n",
        "\n",
        "  # Show the first 10 lines of the cleaned lines\n",
        "  def show_lines(self):\n",
        "    for line in self.cleaned_lines[:10]:\n",
        "      print(line)\n",
        "\n",
        "  # Calculate and return the jaccard distance of A and B\n",
        "  def jaccard_distance(self, A, B):\n",
        "    set_A = set(A.split())\n",
        "    set_B = set(B.split())\n",
        "\n",
        "    intersection_length = len(set_A.intersection(set_B))\n",
        "    union_length = len(set_A.union(set_B))\n",
        "\n",
        "    jaccard_distance = 1 - (intersection_length / union_length)\n",
        "\n",
        "    return jaccard_distance\n",
        "\n",
        "  # Randomly select k tweets indices as centers\n",
        "  def initialize_centers(self, tweets, k):\n",
        "\n",
        "    indices = np.random.choice(len(tweets), k, replace=False)\n",
        "    return indices\n",
        "\n",
        "  def assign_to_clusters(self, tweets, centers):\n",
        "    square_error = []\n",
        "\n",
        "    # Create k lists to store the clusters\n",
        "    clusters = [[i] for i in centers]\n",
        "\n",
        "    # Loop thru all tweets\n",
        "    for index in range(len(tweets)):\n",
        "\n",
        "      if index not in centers:\n",
        "\n",
        "        # Calculate the distance from the current tweet to all k centers\n",
        "        distances = [self.jaccard_distance(tweets[index], tweets[center]) for center in centers]\n",
        "\n",
        "        # Find the index with the smallest distance\n",
        "        min_index_dist = np.argmin(np.array(distances))\n",
        "        # print(min_index_dist)\n",
        "\n",
        "        # Append the index to the correct k list\n",
        "        clusters[min_index_dist].append(index)\n",
        "\n",
        "        # Calculate square of min distance from tweet to center\n",
        "        min_dist = distances[min_index_dist] ** 2\n",
        "\n",
        "        # Append the square of the distance from tweet to center\n",
        "        square_error.append(min_dist)\n",
        "\n",
        "    # Sum of Square error\n",
        "    SSE = sum(square_error)\n",
        "    return clusters, SSE\n",
        "\n",
        "  # Change the centers part of the KMeans algo.\n",
        "  def update_centers(self, tweets, clusters):\n",
        "    centers = []\n",
        "\n",
        "    # Loop thru all clusters\n",
        "    for cluster in clusters:\n",
        "      index_dist_dict = {}\n",
        "\n",
        "      # Find the tweet within that cluster with the smallest distance\n",
        "      # That tweet will be the new center for the cluster\n",
        "      for i in cluster:\n",
        "        total_dist = 0\n",
        "        for j in cluster:\n",
        "          curr_dist = self.jaccard_distance(tweets[i], tweets[j])\n",
        "          total_dist += curr_dist\n",
        "\n",
        "        index_dist_dict[i] = total_dist\n",
        "\n",
        "      # Append the smallest key(index) and will be new center\n",
        "      key, value = min(index_dist_dict.items(), key=lambda item: item[1])\n",
        "      centers.append(key)\n",
        "\n",
        "    return centers\n",
        "\n",
        "  # The KMeans algo. loop\n",
        "  def K_Means(self, tweets, k=5):\n",
        "    SSE_list = []\n",
        "\n",
        "    # Create initial centers and initial clusters\n",
        "    old_centers = self.initialize_centers(tweets, k)\n",
        "    old_clusters, SSE = self.assign_to_clusters(tweets, old_centers)\n",
        "    #print(\"SSE: \", SSE)\n",
        "    SSE_list.append(SSE)\n",
        "\n",
        "    while(1):\n",
        "      # Update centers\n",
        "      new_centers = self.update_centers(tweets, old_clusters)\n",
        "\n",
        "      # Update clusters\n",
        "      new_clusters, SSE = self.assign_to_clusters(tweets, new_centers)\n",
        "      #print(\"SSE: \", SSE)\n",
        "      SSE_list.append(SSE)\n",
        "      #print(\"Old_centers index:\", old_centers, \"New_Centers index:\", new_centers)\n",
        "\n",
        "      # Stops the K_means (return from while loop) if centers didn't change\n",
        "      if set(old_centers) == set(new_centers):\n",
        "        return SSE_list, new_clusters\n",
        "\n",
        "      else:\n",
        "        # Update old_centers to new_centers\n",
        "        # Update old_clusters to new_clusters\n",
        "        old_centers  = new_centers\n",
        "        new_centers = None\n",
        "        old_clusters = new_clusters\n",
        "        new_clusters = None\n",
        "\n",
        "  def show_results(self, SSE_l, c):\n",
        "    k = len(c)\n",
        "    print(\"K:\", k)\n",
        "    print()\n",
        "    i = 0\n",
        "    for cluster in c:\n",
        "      i += 1\n",
        "      print(f\"{i}: {len(cluster)} tweets\")\n",
        "    print(\"SSE:\", SSE_l[-1])\n",
        "\n",
        "  def driver(self, tweets, k=5):\n",
        "    SSE_list, c = self.K_Means(tweets, k=k)\n",
        "    self.show_results(SSE_list, c)"
      ],
      "metadata": {
        "id": "_KcQQPL0cV_N"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TESTING\n",
        "k_means = KMeans()\n",
        "tweets = k_means.read_file(\"everydayhealth.txt\")"
      ],
      "metadata": {
        "id": "-awyjvBXdQqz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_means.driver(tweets, k=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVV51vZ8hLU0",
        "outputId": "8da277cc-71ad-4b42-8339-547be27d9a42"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K: 10\n",
            "\n",
            "1: 304 tweets\n",
            "2: 195 tweets\n",
            "3: 155 tweets\n",
            "4: 890 tweets\n",
            "5: 405 tweets\n",
            "6: 208 tweets\n",
            "7: 84 tweets\n",
            "8: 386 tweets\n",
            "9: 456 tweets\n",
            "10: 156 tweets\n",
            "SSE: 2445.0084706365005\n"
          ]
        }
      ]
    }
  ]
}